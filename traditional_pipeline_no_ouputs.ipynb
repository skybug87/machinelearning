{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d_0BKkpIKhi"
   },
   "source": [
    "# Bird Species Audio Classification Project\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project builds a machine learning model to identify different bird species from their audio recordings. We will analyze bird sounds and create a classifier that can automatically recognize which bird is singing.\n",
    "\n",
    "### What We'll Do:\n",
    "- **Load and explore** bird audio data from Xeno-canto database\n",
    "- **Process audio files** to extract important features\n",
    "- **Build machine learning models** to classify bird species\n",
    "- **Test and evaluate** how well our model works\n",
    "\n",
    "### Dataset:\n",
    "- Audio recordings of 30 different bird species (A-M alphabetically)\n",
    "- Each recording is labeled with the correct bird species\n",
    "- Files are in MP3 format with metadata in CSV file\n",
    "\n",
    "### Models & Techniques Used:\n",
    "- **Convolutional Neural Networks (CNN)** - Custom deep learning model for audio pattern recognition\n",
    "- **YAMNet Classifier** - Google's pre-trained audio classification model\n",
    "- **Mel-frequency spectrograms** - Convert audio to visual representations\n",
    "- **Transfer learning** - Use pre-trained models for better performance\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZIKtM_7IKhm",
    "outputId": "987443aa-3213-47b8-d6cc-41d8356414c6"
   },
   "outputs": [],
   "source": [
    "# Step 1: Initial Setup and Data Exploration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=== BIRD SPECIES AUDIO CLASSIFICATION PROJECT ===\")\n",
    "print(\"Step 1: Initial Setup and Data Exploration\\n\")\n",
    "\n",
    "# Load the metadata CSV\n",
    "print(\"Loading train_extended.csv...\")\n",
    "df = pd.read_csv('/home/sepehr/Documents/Audio-Project/machinelearning/dataset/train_extended.csv')\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Display basic info about the dataset\n",
    "print(\"\\nDATASET OVERVIEW:\")\n",
    "print(\"=\"*50)\n",
    "df.info()\n",
    "\n",
    "print(\"\\nFIRST FEW ROWS:\")\n",
    "print(\"=\"*50)\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nBASIC STATISTICS:\")\n",
    "print(\"=\"*50)\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMISSING VALUES:\")\n",
    "print(\"=\"*50)\n",
    "missing_data = df.isnull().sum()\n",
    "print(missing_data[missing_data > 0])\n",
    "\n",
    "# Explore unique species (ebird_code)\n",
    "print(f\"\\nSPECIES INFORMATION:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total unique species: {df['ebird_code'].nunique()}\")\n",
    "print(f\"Species list: {sorted(df['ebird_code'].unique())}\")\n",
    "\n",
    "# Check rating distribution\n",
    "print(f\"\\nRATING DISTRIBUTION:\")\n",
    "print(\"=\"*50)\n",
    "rating_counts = df['rating'].value_counts().sort_index()\n",
    "print(rating_counts)\n",
    "\n",
    "# Check duration statistics\n",
    "print(f\"\\nDURATION STATISTICS:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Min duration: {df['duration'].min():.2f}s\")\n",
    "print(f\"Max duration: {df['duration'].max():.2f}s\")\n",
    "print(f\"Mean duration: {df['duration'].mean():.2f}s\")\n",
    "print(f\"Median duration: {df['duration'].median():.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmxM5HJoIKho"
   },
   "source": [
    "## Step 1: Initial Setup and Data Exploration\n",
    "\n",
    "### What We're Doing:\n",
    "- Loading the bird audio dataset\n",
    "- Exploring the data structure and basic statistics\n",
    "- Understanding what information we have about each bird recording\n",
    "\n",
    "### Key Libraries:\n",
    "- **pandas** - For data handling and analysis\n",
    "- **numpy** - For numerical operations\n",
    "- **matplotlib & seaborn** - For creating charts and visualizations\n",
    "- **os** - For file operations\n",
    "\n",
    "### What to Expect:\n",
    "- Dataset contains **23,784 bird recordings** from **30 species**\n",
    "- Each recording has **29 features** including species name, duration, location, etc.\n",
    "- Audio files range from very short clips to long recordings (up to 59 minutes!)\n",
    "- Most recordings are around **31 seconds** long (median duration)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zQMdrzYzIKhp",
    "outputId": "35df741f-0e48-4f74-9174-633085fa25cb"
   },
   "outputs": [],
   "source": [
    "# Step 2: Data Visualization and Configuration Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=== STEP 2: DATA VISUALIZATION & CONFIGURATION ===\\n\")\n",
    "\n",
    "# ========================================\n",
    "# CONFIGURATION PARAMETERS (EASILY ADJUSTABLE)\n",
    "# ========================================\n",
    "CONFIG = {\n",
    "    'MIN_RATING_THRESHOLD': 3.0,      # Filter recordings below this rating #crystal\n",
    "    #'NUM_CLASSES': 30,                # Number of bird species to use (3, 5, 30, or custom) this value should be calculated #crystal\n",
    "    'MAX_DURATION': 20,              # Maximum duration in seconds (20 seconds) #crystal\n",
    "    'MIN_DURATION': 1,                # Minimum duration in seconds, if its 0 then theres nothing #crystal\n",
    "    'MIN_SAMPLES_PER_CLASS': 100,      # Minimum samples needed per species #crystal\n",
    "}\n",
    "\n",
    "print(\"CURRENT CONFIGURATION:\")\n",
    "print(\"=\"*50)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"DATA ANALYSIS BEFORE FILTERING:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Rating Distribution Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Rating distribution\n",
    "axes[0,0].hist(df['rating'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].axvline(CONFIG['MIN_RATING_THRESHOLD'], color='red', linestyle='--',\n",
    "                 label=f'Min Rating Threshold: {CONFIG[\"MIN_RATING_THRESHOLD\"]}')\n",
    "axes[0,0].set_xlabel('Rating')\n",
    "axes[0,0].set_ylabel('Count')\n",
    "axes[0,0].set_title('Rating Distribution')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Duration distribution\n",
    "axes[0,1].hist(df['duration'], bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[0,1].axvline(CONFIG['MAX_DURATION'], color='red', linestyle='--',\n",
    "                 label=f'Max Duration: {CONFIG[\"MAX_DURATION\"]}s')\n",
    "axes[0,1].axvline(CONFIG['MIN_DURATION'], color='orange', linestyle='--',\n",
    "                 label=f'Min Duration: {CONFIG[\"MIN_DURATION\"]}s')\n",
    "axes[0,1].set_xlabel('Duration (seconds)')\n",
    "axes[0,1].set_ylabel('Count')\n",
    "axes[0,1].set_title('Duration Distribution')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "axes[0,1].set_xlim(0, 500)  # Focus on reasonable duration range\n",
    "\n",
    "# Species count distribution\n",
    "species_counts = df['ebird_code'].value_counts().head(153) #crystal\n",
    "\n",
    "axes[1,0].hist(species_counts.values, bins=30, alpha=0.7, color='coral', edgecolor='black')\n",
    "axes[1,0].axvline(CONFIG['MIN_SAMPLES_PER_CLASS'], color='red', linestyle='--',\n",
    "                 label=f'Min Samples: {CONFIG[\"MIN_SAMPLES_PER_CLASS\"]}')\n",
    "axes[1,0].set_xlabel('Number of Samples per Species')\n",
    "axes[1,0].set_ylabel('Number of Species')\n",
    "axes[1,0].set_title('Samples per Species Distribution')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Channel distribution\n",
    "channel_counts = df['channels'].value_counts()\n",
    "axes[1,1].pie(channel_counts.values, labels=channel_counts.index, autopct='%1.1f%%',\n",
    "             colors=['lightblue', 'lightcoral'])\n",
    "axes[1,1].set_title('Channel Distribution')\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "# 2. Detailed Species Analysis\n",
    "print(f\"\\nSPECIES STATISTICS:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total species: {species_counts.shape[0]}\")\n",
    "\n",
    "# Filter the original DataFrame to keep only those species\n",
    "# Get the top 153 ebird_codes\n",
    "# Step 1: Get value counts (i.e., frequency) of unique values\n",
    "value_counts = df['ebird_code'].value_counts()\n",
    "\n",
    "print(\"value counts: \", value_counts)\n",
    "\n",
    "# Step 2: Sort the index (unique values) alphabetically\n",
    "value_counts_sorted = value_counts.sort_index()\n",
    "\n",
    "print(\"value counts sorted: \", value_counts_sorted)\n",
    "\n",
    "top_153_unique = value_counts_sorted[:153]\n",
    "\n",
    "print(\"value counts sorted am: \", top_153_unique)\n",
    "\n",
    "\n",
    "# Step 2: Filter to keep only ebird_codes with at least 100 occurrences\n",
    "valid_codes = value_counts[value_counts > CONFIG['MIN_SAMPLES_PER_CLASS']].index\n",
    "\n",
    "# Step 5: Get all rows from the original df with those top ebird_codes\n",
    "filtered_df = df[df['ebird_code'].isin(top_153_unique.index)]\n",
    "\n",
    "\n",
    "print(\"filter data with top 153: \", top_153_unique)\n",
    "display(filtered_df)\n",
    "\n",
    "\n",
    "print(\"filter data with atleast 100 samples in 153: \")\n",
    "# Step 5: Get all rows from the original df with those top ebird_codes\n",
    "filtered_df = filtered_df[filtered_df['ebird_code'].isin(valid_codes)]\n",
    "species_counts = filtered_df ['ebird_code'].value_counts()\n",
    "print(f\"number of species  with 100 samples: \", species_counts.shape[0])\n",
    "display(filtered_df)\n",
    "\n",
    "updatedvalue_counts = filtered_df['ebird_code'].value_counts()\n",
    "print(\"updated species value counts sorted a to m: \", updatedvalue_counts)\n",
    "\n",
    "\n",
    "\n",
    "# 3. Apply Filters and Show Impact\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"APPLYING FILTERS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Filter by duration\n",
    "filtered_df = filtered_df[filtered_df['duration'] < 20]\n",
    "species_counts = filtered_df ['ebird_code'].value_counts()\n",
    "print(f\"number of species  with duration < 20: \", species_counts.shape[0])\n",
    "display(filtered_df)\n",
    "\n",
    "# Filter by rating\n",
    "filtered_df = filtered_df[filtered_df['rating'] > 3]\n",
    "species_counts = filtered_df['ebird_code'].value_counts()\n",
    "print(f\"number of species  with rating > 3: \", species_counts.shape[0])\n",
    "display(filtered_df)\n",
    "\n",
    "# Remove rows where 'url' is missing or empty\n",
    "filtered_df = filtered_df[filtered_df['url'].notna() & (filtered_df['url'].str.strip() != '')]\n",
    "\n",
    "print(f\"Remaining rows after removing missing/empty URLs: {len(filtered_df)}\")\n",
    "print(f\"number of species  that contain url data \", species_counts.shape[0])\n",
    "display(filtered_df)\n",
    "\n",
    "print(f\"number of species COUNTS \", species_counts)\n",
    "\n",
    "# # 4. Select Top N Classes\n",
    "# print(f\"\\n{'='*50}\")\n",
    "# print(f\"SELECTING TOP {CONFIG['NUM_CLASSES']} CLASSES:\")\n",
    "# print(\"=\"*50)\n",
    "\n",
    "# Get top N species by sample count (after filtering)\n",
    "#final_species_counts = df_filtered['ebird_code'].value_counts().head(153) #crystal\n",
    "# if CONFIG['NUM_CLASSES'] <= len(final_species_counts):\n",
    "#     selected_species = final_species_counts.head(CONFIG['NUM_CLASSES']).index.tolist()\n",
    "#     df_final = df_filtered[df_filtered['ebird_code'].isin(selected_species)].copy()\n",
    "\n",
    "#     print(f\"Selected {len(selected_species)} species:\")\n",
    "#     for i, species in enumerate(selected_species, 1):\n",
    "#         count = final_species_counts[species]\n",
    "#         print(f\"{i:2d}. {species}: {count:3d} samples\")\n",
    "\n",
    "#     print(f\"\\nFinal dataset: {len(df_final):,} samples across {len(selected_species)} species\")\n",
    "\n",
    "#     # Class balance visualization\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     final_counts = df_final['ebird_code'].value_counts()\n",
    "#     plt.bar(range(len(final_counts)), final_counts.values, color='steelblue', alpha=0.7)\n",
    "#     plt.xlabel('Species (ordered by sample count)')\n",
    "#     plt.ylabel('Number of Samples')\n",
    "#     plt.title(f'Class Distribution - Top {CONFIG[\"NUM_CLASSES\"]} Species (After Filtering)')\n",
    "#     plt.xticks(range(len(final_counts)), final_counts.index, rotation=45, ha='right')\n",
    "#     plt.grid(True, alpha=0.3)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     # Calculate class imbalance ratio\n",
    "#     max_samples = final_counts.max()\n",
    "#     min_samples = final_counts.min()\n",
    "#     imbalance_ratio = max_samples / min_samples\n",
    "#     print(f\"\\nClass imbalance ratio: {imbalance_ratio:.2f} (max: {max_samples}, min: {min_samples})\")\n",
    "\n",
    "# else:\n",
    "#     print(f\" Not enough species meet the criteria! Only {len(final_species_counts)} species available.\")\n",
    "#     print(\"Consider reducing MIN_SAMPLES_PER_CLASS or NUM_CLASSES\")\n",
    "\n",
    "# # 5. Save configuration and filtered dataset info\n",
    "# print(f\"\\n{'='*50}\")\n",
    "# print(\"SUMMARY FOR NEXT STEPS:\")\n",
    "# print(\"=\"*50)\n",
    "# print(f\" Configuration set for {CONFIG['NUM_CLASSES']} classes\")\n",
    "# print(f\" {len(df_final):,} total samples after filtering\")\n",
    "# print(f\" Rating threshold: ≥{CONFIG['MIN_RATING_THRESHOLD']}\")\n",
    "# print(f\" Duration range: {CONFIG['MIN_DURATION']}-{CONFIG['MAX_DURATION']} seconds\")\n",
    "# print(f\" Ready for audio file validation and preprocessing\")\n",
    "\n",
    "# # Create a summary for the next step\n",
    "# STEP2_SUMMARY = {\n",
    "#     'df_final': df_final,\n",
    "#     'selected_species': selected_species,\n",
    "#     'config': CONFIG,\n",
    "#     'class_counts': final_counts.to_dict()\n",
    "# }\n",
    "\n",
    "print(f\"\\n Next step: Audio file validation and path checking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzECnlCOIKhr"
   },
   "source": [
    "## Step 2: Data Visualization and Configuration Setup\n",
    "\n",
    "### What We're Doing:\n",
    "- Setting up **filters** to clean our data and keep only high-quality recordings\n",
    "- Creating **visualizations** to understand our dataset better\n",
    "- Selecting the **best bird species** for our classification model\n",
    "\n",
    "### Configuration Settings:\n",
    "We set up important thresholds to filter our data:\n",
    "- **Rating ≥ 2.0** - Only keep good quality recordings\n",
    "- **Duration 5-300 seconds** - Remove very short or very long clips\n",
    "- **≥20 samples per species** - Ensure we have enough data for each bird\n",
    "- **Top 30 species** - Focus on the most common birds\n",
    "\n",
    "### Key Insights from Visualizations:\n",
    "- **Rating Distribution**: Most recordings have ratings between 3-4 (good quality)\n",
    "- **Duration**: Most clips are under 100 seconds, with many very short recordings\n",
    "- **Species Balance**: Some bird species have many more recordings than others\n",
    "- **Audio Quality**: About 57% are stereo, 43% are mono recordings\n",
    "\n",
    "### Final Dataset After Filtering:\n",
    "- **11,725 total samples** from **30 bird species**\n",
    "- **Class imbalance ratio: 8.84** (most common species has 8.84x more samples than least common)\n",
    "- **Top species**: Red Crossbill (1,397 samples), House Sparrow (1,085 samples)\n",
    "- **Least represented**: Great Horned Owl (158 samples), House Finch (163 samples)\n",
    "\n",
    "### Why These Filters Matter:\n",
    "- **Better model performance** - High-quality data leads to better predictions\n",
    "- **Balanced training** - Each species needs enough examples to learn from\n",
    "- **Consistent audio length** - Helps our model process audio more effectively\n",
    "- **Quality control** - Only keeping recordings rated 2.0+ ensures good audio quality\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZVJdaXISuJ5",
    "outputId": "75847652-6075-428a-fd72-f3e3717bfd47"
   },
   "outputs": [],
   "source": [
    "# Step 3: Audio File Validation and Processing Setup\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "\n",
    "print(\"=== STEP 3: AUDIO FILE VALIDATION & PROCESSING SETUP ===\\n\")\n",
    "\n",
    "# # Use the filtered dataset from Step 2\n",
    "# # For this step, we'll work with the configuration from Step 2\n",
    "# CONFIG = {\n",
    "#     'MIN_RATING_THRESHOLD': 2.0,\n",
    "#     'NUM_CLASSES': 30,\n",
    "#     'MAX_DURATION': 300,\n",
    "#     'MIN_DURATION': 5,\n",
    "#     'MIN_SAMPLES_PER_CLASS': 20,\n",
    "# }\n",
    "\n",
    "# # Re-apply the same filtering logic to recreate df_final\n",
    "# print(\"Recreating filtered dataset...\")\n",
    "# df_filtered = df[df['rating'] >= CONFIG['MIN_RATING_THRESHOLD']].copy()\n",
    "# df_filtered = df_filtered[\n",
    "#     (df_filtered['duration'] >= CONFIG['MIN_DURATION']) &\n",
    "#     (df_filtered['duration'] <= CONFIG['MAX_DURATION'])\n",
    "# ].copy()\n",
    "\n",
    "# species_counts_filtered = df_filtered['ebird_code'].value_counts()\n",
    "# valid_species = species_counts_filtered[species_counts_filtered >= CONFIG['MIN_SAMPLES_PER_CLASS']].index\n",
    "# df_filtered = df_filtered[df_filtered['ebird_code'].isin(valid_species)].copy()\n",
    "\n",
    "# final_species_counts = df_filtered['ebird_code'].value_counts()\n",
    "# selected_species = final_species_counts.head(CONFIG['NUM_CLASSES']).index.tolist()\n",
    "# df_final = df_filtered[df_filtered['ebird_code'].isin(selected_species)].copy()\n",
    "\n",
    "# print(f\"Filtered dataset ready: {len(df_final)} samples, {len(selected_species)} species\")\n",
    "\n",
    "final_species_counts = filtered_df['ebird_code'].value_counts()\n",
    "selected_species = final_species_counts.index.tolist()\n",
    "\n",
    "# ========================================\n",
    "# 1. FIND AUDIO FILES AND VALIDATE PATHS\n",
    "# ========================================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"AUDIO FILE PATH VALIDATION:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Look for the audio files\n",
    "base_path = Path('dataset/raw/train_extended.csv')\n",
    "print(f\"Base path: {base_path}\")\n",
    "print(f\"Base path exists: {base_path.exists()}\")\n",
    "\n",
    "\n",
    "# print(f\"\\nDirectories containing MP3 files:\")\n",
    "# for mp3_dir in mp3_dirs[:5]:  # Show first 5\n",
    "#     mp3_count = len([f for f in os.listdir(mp3_dir) if f.endswith('.mp3')])\n",
    "#     print(f\"  - {mp3_dir}: {mp3_count} MP3 files\")\n",
    "\n",
    "# if len(mp3_dirs) > 5:\n",
    "#     print(f\"  ... and {len(mp3_dirs)-5} more directories\")\n",
    "\n",
    "# ========================================\n",
    "# 2. CREATE FULL FILE PATHS\n",
    "# ========================================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"CREATING FILE PATHS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def find_audio_file_path(filename, base_dirs):\n",
    "    \"\"\"Find the full path of an audio file\"\"\"\n",
    "    for base_dir in base_dirs:\n",
    "        full_path = os.path.join(base_dir, filename)\n",
    "        if os.path.exists(full_path):\n",
    "            return full_path\n",
    "    return None\n",
    "\n",
    "\n",
    "# Check how many files we found\n",
    "files_found = filtered_df['url'].notna().sum()\n",
    "files_missing = filtered_df['url'].isna().sum()\n",
    "\n",
    "print(f\"Files found: {files_found}\")\n",
    "print(f\"Files missing: {files_missing}\")\n",
    "print(f\"Success rate: {files_found/(files_found+files_missing)*100:.1f}%\")\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 3. AUDIO VALIDATION AND BASIC ANALYSIS\n",
    "# ========================================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"AUDIO FILE VALIDATION:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test loading a few random audio files\n",
    "\n",
    "filtered_df['download_url'] = filtered_df['url'].astype(str).str.rstrip('/') + '/download'\n",
    "\n",
    "sample_files = filtered_df.sample(n=min(5, len(filtered_df)))\n",
    "\n",
    "# Create a directory to store downloaded audio\n",
    "os.makedirs(\"temp_audio\", exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "audio_info = []\n",
    "\n",
    "for idx, row in sample_files.iterrows():\n",
    "    try:\n",
    "\n",
    "\n",
    "        # Get file name from URL\n",
    "        url = row['download_url']\n",
    "        filename = os.path.join(\"temp_audio\", url.split(\"/\")[-2] + '.mp3')\n",
    "\n",
    "        # Download if not already present\n",
    "        if not os.path.exists(filename):\n",
    "            urllib.request.urlretrieve(url, filename)\n",
    "            print(f\"Downloaded: {filename}\")\n",
    "\n",
    "        # Load audio\n",
    "        audio, sr = librosa.load(filename, sr=None, duration=10)\n",
    "        duration = len(audio) / sr\n",
    "        print(\"Testing audio file loading...\")\n",
    "\n",
    "        info = {\n",
    "            'filename': row['filename'],\n",
    "            'species': row['ebird_code'],\n",
    "            'csv_duration': row['duration'],\n",
    "            'actual_duration': duration,\n",
    "            'sample_rate': sr,\n",
    "            'channels_csv': row['channels'],\n",
    "            'audio_shape': audio.shape,\n",
    "            'success': True\n",
    "        }\n",
    "        audio_info.append(info)\n",
    "        print(f\" {row['download_url']}: {duration:.1f}s, {sr}Hz, shape={audio.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        info = {\n",
    "            'filename': row['url'],\n",
    "            'species': row['ebird_code'],\n",
    "            'error': str(e),\n",
    "            'success': False\n",
    "        }\n",
    "        audio_info.append(info)\n",
    "        print(f\" {row['url']}: Error - {str(e)}\")\n",
    "\n",
    "# ========================================\n",
    "# 4. DATASET SPLIT PREPARATION\n",
    "# ========================================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"DATASET SPLIT PREPARATION:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create class mapping\n",
    "class_mapping = {species: idx for idx, species in enumerate(selected_species )}\n",
    "reverse_mapping = {idx: species for species, idx in class_mapping.items()}\n",
    "\n",
    "print(\"Class mapping created:\")\n",
    "for species, idx in list(class_mapping.items())[:5]:\n",
    "    print(f\"  {idx}: {species}\")\n",
    "print(f\"  ... (showing first 5 of {len(class_mapping)} classes)\")\n",
    "\n",
    "# Add numeric labels\n",
    "filtered_df['class_id'] = filtered_df['ebird_code'].map(class_mapping)\n",
    "\n",
    "# Prepare for stratified split\n",
    "print(f\"\\nPreparing stratified split...\")\n",
    "print(f\"Class distribution before split:\")\n",
    "class_dist = filtered_df['ebird_code'].value_counts()\n",
    "print(class_dist.head(10))\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 5. AUDIO PROCESSING CONFIGURATION\n",
    "# ========================================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"AUDIO PROCESSING CONFIGURATION:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "AUDIO_CONFIG = {\n",
    "    'SAMPLE_RATE': 22050,           # Standard sample rate for audio ML\n",
    "    'MAX_AUDIO_LENGTH': 10,         # Maximum audio length in seconds\n",
    "    'N_MELS': 128,                  # Number of mel bands for spectrogram\n",
    "    'N_FFT': 2048,                  # FFT window size\n",
    "    'HOP_LENGTH': 512,              # Hop length for STFT\n",
    "    'SPECTROGRAM_HEIGHT': 128,      # Height of spectrogram image\n",
    "    'SPECTROGRAM_WIDTH': 432,       # Width of spectrogram image (for 10s audio)\n",
    "}\n",
    "\n",
    "print(\"Audio processing configuration:\")\n",
    "for key, value in AUDIO_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Calculate expected spectrogram dimensions\n",
    "expected_time_steps = (AUDIO_CONFIG['MAX_AUDIO_LENGTH'] * AUDIO_CONFIG['SAMPLE_RATE']) // AUDIO_CONFIG['HOP_LENGTH']\n",
    "print(f\"\\nExpected spectrogram shape: ({AUDIO_CONFIG['N_MELS']}, {expected_time_steps})\")\n",
    "\n",
    "# ========================================\n",
    "# 6. SUMMARY FOR NEXT STEPS\n",
    "# ========================================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"STEP 3 SUMMARY:\")\n",
    "print(\"=\"*50)\n",
    "print(f\" Audio files validated: {files_found}/{files_found+files_missing} found\")\n",
    "print(f\" Dataset ready: {len(filtered_df)} samples\")\n",
    "print(f\" Classes: {len(selected_species)} species\")\n",
    "print(f\" Class mapping created\")\n",
    "print(f\" Audio processing config set\")\n",
    "print(f\" Ready for train/validation/test split\")\n",
    "\n",
    "# Save some key info for next step\n",
    "STEP3_INFO = {\n",
    "    'df_final': filtered_df,\n",
    "    'class_mapping': class_mapping,\n",
    "    'reverse_mapping': reverse_mapping,\n",
    "    'selected_species': selected_species,\n",
    "    'audio_config': AUDIO_CONFIG,\n",
    "    'config': CONFIG\n",
    "}\n",
    "\n",
    "print(f\"\\n Next step: Train/Validation/Test split and first audio preprocessing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPAjaA3cU3HF"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MrLV_Ye1IKht"
   },
   "source": [
    "## Step 3: Audio File Validation and Processing Setup\n",
    "\n",
    "### What We're Doing:\n",
    "- **Finding audio files** in the dataset folders and checking if they exist\n",
    "- **Creating file paths** so our code knows where each audio recording is stored\n",
    "- **Testing audio loading** to make sure we can read the files correctly\n",
    "- **Setting up audio processing** parameters for converting sound to spectrograms\n",
    "\n",
    "### Key Audio Processing Settings:\n",
    "- **Sample rate**: 22,050 Hz (standard for machine learning)\n",
    "- **Max length**: 10 seconds per audio clip\n",
    "- **Spectrogram size**: 128 x 432 pixels (converts sound to image format)\n",
    "- **Mel bands**: 128 frequency bands (captures important audio features)\n",
    "\n",
    "### Validation Results:\n",
    "- **Audio files found**: Successfully located MP3 files in 153 directories\n",
    "- **File structure**: Audio organized by species (A-M folder contains subfolders for each bird)\n",
    "- **Loading test**: Audio files can be read properly with correct sample rates and durations\n",
    "- **Class mapping**: Created numeric labels (0-29) for each of the 30 bird species\n",
    "\n",
    "### Why This Step Matters:\n",
    "- **File verification** - Ensures all audio files exist and can be loaded\n",
    "- **Standardization** - Sets consistent audio processing parameters\n",
    "- **Organization** - Maps species names to numbers for machine learning\n",
    "- **Quality check** - Tests that audio data matches the CSV information\n",
    "\n",
    "### Next Steps Ready:\n",
    "- All 11,725 audio samples are accessible and validated\n",
    "- Audio processing configuration is set for consistent training\n",
    "- Dataset is ready to be split into training, validation, and test sets\n",
    "\n",
    "### Links to Data:\n",
    "- Bird Audio Filtered Files output: https://drive.google.com/drive/folders/1s8IkzkHDz_2Pnb_OLzlBkT54iRMhkszx?usp=sharing\n",
    "\n",
    "- Spectrogram output: https://drive.google.com/drive/folders/1sWf2GzTZ5ELXiIt6razSTtYN54haC1bQ?usp=drive_link\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 Modified: Data Split and Audio Preprocessing (No External Dependencies)\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Hotfix for deprecated NumPy types used in older librosa versions\n",
    "np.complex = np.complex128\n",
    "np.float = float\n",
    "np.int = int\n",
    "np.bool = bool\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "from scipy.signal import butter, filtfilt\n",
    "import warnings\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError, URLError\n",
    "import time\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "GDRIVE_AUDIO_DIR = '/home/sepehr/Documents/Audio-Project/machinelearning/dataset/filtered/birdaudio'\n",
    "os.makedirs(GDRIVE_AUDIO_DIR, exist_ok=True)\n",
    "\n",
    "GDRIVE_MELSPEC_DIR = '/home/sepehr/Documents/Audio-Project/machinelearning/dataset/filtered/melspec'\n",
    "os.makedirs(GDRIVE_MELSPEC_DIR, exist_ok=True)\n",
    "\n",
    "print(\"=== STEP 4: DATA SPLIT & AUDIO PREPROCESSING (MODIFIED) ===\\n\")\n",
    "\n",
    "AUDIO_CONFIG = {\n",
    "    'SAMPLE_RATE': 22050,\n",
    "    'MAX_AUDIO_LENGTH': 10,\n",
    "    'N_MELS': 128,\n",
    "    'N_FFT': 2048,\n",
    "    'HOP_LENGTH': 512,\n",
    "    'SPECTROGRAM_HEIGHT': 128,\n",
    "    'SPECTROGRAM_WIDTH': 432,\n",
    "}\n",
    "# ========================================\n",
    "# 1. STRATIFIED TRAIN/VALIDATION/TEST SPLIT\n",
    "# ========================================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"STRATIFIED DATA SPLIT:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# First split: train+val vs test (80/20)\n",
    "X = filtered_df[['download_url', 'filename', 'ebird_code']].copy()\n",
    "y = filtered_df['class_id'].copy()\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: train vs validation (75/25 of remaining = 60/20 of total)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Data split completed:\")\n",
    "print(f\"  Training set:   {len(X_train):,} samples ({len(X_train)/len(filtered_df)*100:.1f}%)\")\n",
    "print(f\"  Validation set: {len(X_val):,} samples ({len(X_val)/len(filtered_df)*100:.1f}%)\")\n",
    "print(f\"  Test set:       {len(X_test):,} samples ({len(X_test)/len(filtered_df)*100:.1f}%)\")\n",
    "\n",
    "# Verify class distribution is maintained\n",
    "print(f\"\\nClass distribution verification:\")\n",
    "train_dist = y_train.value_counts().sort_index()\n",
    "val_dist = y_val.value_counts().sort_index()\n",
    "test_dist = y_test.value_counts().sort_index()\n",
    "\n",
    "sample_classes = train_dist.index[:5]\n",
    "for class_id in sample_classes:\n",
    "    species = selected_species[class_id]\n",
    "    total_samples = train_dist[class_id] + val_dist[class_id] + test_dist[class_id]\n",
    "    train_pct = train_dist[class_id] / total_samples * 100\n",
    "    val_pct = val_dist[class_id] / total_samples * 100\n",
    "    test_pct = test_dist[class_id] / total_samples * 100\n",
    "    print(f\"  {species}: Train={train_pct:.1f}%, Val={val_pct:.1f}%, Test={test_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nNDF7gBNCzz4",
    "jp-MarkdownHeadingCollapsed": true,
    "outputId": "3857031b-3cba-44cd-c0c0-70560536ac7a"
   },
   "source": [
    "# ========================================\n",
    "# 2. AUDIO PREPROCESSING FUNCTIONS\n",
    "# ========================================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"AUDIO PREPROCESSING FUNCTIONS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def apply_highpass_filter(audio, sr, cutoff_freq=300):\n",
    "    \"\"\"Apply high-pass filter to remove low-frequency noise\"\"\"\n",
    "    nyquist = sr / 2\n",
    "    normalized_cutoff = cutoff_freq / nyquist\n",
    "    if normalized_cutoff >= 1.0:\n",
    "        normalized_cutoff = 0.99  # Prevent error if cutoff too high\n",
    "    b, a = butter(5, normalized_cutoff, btype='high')\n",
    "    filtered_audio = filtfilt(b, a, audio)\n",
    "    return filtered_audio\n",
    "\n",
    "def apply_bandpass_filter(audio, sr, low_freq=300, high_freq=8000):\n",
    "    \"\"\"Apply band-pass filter to keep bird frequency range\"\"\"\n",
    "    nyquist = sr / 2\n",
    "    low_normalized = low_freq / nyquist\n",
    "    high_normalized = high_freq / nyquist\n",
    "\n",
    "    # Ensure frequencies are in valid range\n",
    "    low_normalized = max(0.01, min(low_normalized, 0.99))\n",
    "    high_normalized = max(low_normalized + 0.01, min(high_normalized, 0.99))\n",
    "\n",
    "    b, a = butter(5, [low_normalized, high_normalized], btype='band')\n",
    "    filtered_audio = filtfilt(b, a, audio)\n",
    "    return filtered_audio\n",
    "\n",
    "def reduce_noise_spectral_subtraction(audio, sr, noise_factor=0.5):\n",
    "    \"\"\"Simple spectral subtraction for noise reduction\"\"\"\n",
    "    try:\n",
    "        # Convert to frequency domain\n",
    "        fft = np.fft.fft(audio)\n",
    "        magnitude = np.abs(fft)\n",
    "        phase = np.angle(fft)\n",
    "\n",
    "        # Estimate noise from the first 10% of the signal\n",
    "        noise_length = len(audio) // 10\n",
    "        noise_magnitude = np.mean(np.abs(np.fft.fft(audio[:noise_length])))\n",
    "\n",
    "        # Subtract noise estimate\n",
    "        clean_magnitude = magnitude - noise_factor * noise_magnitude\n",
    "        clean_magnitude = np.maximum(clean_magnitude, 0.1 * magnitude)  # Floor at 10% of original\n",
    "\n",
    "        # Reconstruct signal\n",
    "        clean_fft = clean_magnitude * np.exp(1j * phase)\n",
    "        clean_audio = np.real(np.fft.ifft(clean_fft))\n",
    "\n",
    "        return clean_audio\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Spectral subtraction failed, returning filtered audio. Error: {e}\")\n",
    "        return audio\n",
    "\n",
    "def normalize_audio(audio):\n",
    "    \"\"\"Normalize audio to [-1, 1] range\"\"\"\n",
    "    if np.max(np.abs(audio)) > 0:\n",
    "        return audio / np.max(np.abs(audio))\n",
    "    return audio\n",
    "\n",
    "def load_and_preprocess_audio(file_path, target_sr=22050, max_length=10):\n",
    "    \"\"\"Load and preprocess a single audio file\"\"\"\n",
    "    try:\n",
    "        # Load audio\n",
    "        filename = os.path.join(\"temp_audio\", url.split(\"/\")[-2] + '.mp3')\n",
    "\n",
    "\n",
    "\n",
    "        # Load audio\n",
    "        #audio, sr = librosa.load(filename, sr=None, duration=10)\n",
    "        audio, sr = librosa.load(filename, sr=target_sr, duration=max_length)\n",
    "\n",
    "        # Apply band-pass filter to focus on bird frequency range\n",
    "        audio_filtered = apply_bandpass_filter(audio, sr, low_freq=300, high_freq=8000)\n",
    "\n",
    "        # Apply simple noise reduction\n",
    "        audio_denoised = reduce_noise_spectral_subtraction(audio_filtered, sr)\n",
    "\n",
    "        # Normalize\n",
    "        audio_normalized = normalize_audio(audio_denoised)\n",
    "\n",
    "        # Ensure consistent length (pad or truncate)\n",
    "        target_length = int(max_length * target_sr)\n",
    "        if len(audio_normalized) < target_length:\n",
    "            # Pad with zeros\n",
    "            audio_normalized = np.pad(audio_normalized, (0, target_length - len(audio_normalized)))\n",
    "        else:\n",
    "            # Truncate\n",
    "            audio_normalized = audio_normalized[:target_length]\n",
    "\n",
    "        return audio_normalized, sr\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None, None\n",
    "def save_melspectrogram_to_drive(audio, sr, ebird_code, rec_id, base_dir=GDRIVE_MELSPEC_DIR):\n",
    "    try:\n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            y=audio,\n",
    "            sr=sr,\n",
    "            n_mels=AUDIO_CONFIG['N_MELS'],\n",
    "            n_fft=AUDIO_CONFIG['N_FFT'],\n",
    "            hop_length=AUDIO_CONFIG['HOP_LENGTH'],\n",
    "            power=2.0\n",
    "        )\n",
    "        mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "        filename = f\"{ebird_code}_{rec_id}.npy\"\n",
    "        filepath = os.path.join(base_dir, filename)\n",
    "\n",
    "        if not os.path.exists(filepath):\n",
    "            np.save(filepath, mel_db)\n",
    "            print(f\"Saved mel-spec to: {filepath}\")\n",
    "        else:\n",
    "            print(f\"Skipped (already exists): {filepath}\")\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Failed saving mel-spec for {rec_id}: {e}\")\n",
    "        return False\n",
    "def audio_to_melspectrogram(audio, sr, n_mels=128, n_fft=2048, hop_length=512):\n",
    "    try:\n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            y=audio,\n",
    "            sr=sr,\n",
    "            n_mels=n_mels,\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            power=2.0\n",
    "        )\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        return mel_spec_db\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating spectrogram: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "print(\"Audio preprocessing functions defined:\")\n",
    "print(\"  - Band-pass filtering (300-8000 Hz for bird sounds)\")\n",
    "print(\"  - Spectral subtraction noise reduction\")\n",
    "print(\"  - Audio normalization\")\n",
    "print(\"  - Mel-spectrogram generation\")\n",
    "\n",
    "\n",
    "def fetch_to_drive(url: str, base_folder=GDRIVE_AUDIO_DIR, max_retry=3, sleep_secs=0):\n",
    "    \"\"\"Download audio to Google Drive\"\"\"\n",
    "    rec_id = url.rstrip(\"/\").split(\"/\")[-2]\n",
    "    local_path = os.path.join(base_folder, f\"{rec_id}.mp3\")\n",
    "\n",
    "    if os.path.exists(local_path):\n",
    "        return local_path  # already downloaded\n",
    "\n",
    "    for attempt in range(max_retry):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, local_path)\n",
    "            return local_path\n",
    "        except (HTTPError, URLError) as e:\n",
    "            print(f\"   ⚠️  {rec_id}: {e} (attempt {attempt+1}/{max_retry})\")\n",
    "            time.sleep(sleep_secs)\n",
    "\n",
    "    return None\n",
    "# ========================================\n",
    "# 3. TEST PREPROCESSING ON SAMPLE FILES\n",
    "# ========================================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"TESTING PREPROCESSING PIPELINE:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "datasets = [X_train, X_val, X_test]\n",
    "for dataset in datasets:\n",
    "    n_samples = len(dataset)\n",
    "    if n_samples == 0:\n",
    "        continue\n",
    "\n",
    "    for idx, (_, row) in enumerate(dataset.iterrows()):\n",
    "        url = row['download_url']\n",
    "        species = row['ebird_code']\n",
    "\n",
    "        file_mp3 = fetch_to_drive(url)\n",
    "        if file_mp3 is None or not os.path.exists(file_mp3):\n",
    "            print(f\"Skipping {species} — could not fetch or does not exist.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing sample {idx+1}/{n_samples}: {url} ({species})\")\n",
    "\n",
    "        try:\n",
    "            original_audio, sr = librosa.load(file_mp3, sr=AUDIO_CONFIG['SAMPLE_RATE'], duration=3)\n",
    "\n",
    "            filtered_audio = apply_bandpass_filter(original_audio, sr)\n",
    "            denoised_audio = reduce_noise_spectral_subtraction(filtered_audio, sr)\n",
    "            final_audio = normalize_audio(denoised_audio)\n",
    "\n",
    "            rec_id = url.rstrip(\"/\").split(\"/\")[-2]\n",
    "            mel_file_path = os.path.join(GDRIVE_MELSPEC_DIR, f\"{species}_{rec_id}.npy\") \n",
    "\n",
    "            if os.path.exists(mel_file_path):\n",
    "                print(f\"Skipping {species}/{rec_id} — already saved.\")\n",
    "                continue\n",
    "\n",
    "            original_spec = audio_to_melspectrogram(original_audio, sr,\n",
    "                                                    AUDIO_CONFIG['N_MELS'], AUDIO_CONFIG['N_FFT'], AUDIO_CONFIG['HOP_LENGTH'])\n",
    "            final_spec = audio_to_melspectrogram(final_audio, sr,\n",
    "                                                 AUDIO_CONFIG['N_MELS'], AUDIO_CONFIG['N_FFT'], AUDIO_CONFIG['HOP_LENGTH'])\n",
    "\n",
    "            if final_spec is not None:\n",
    "                np.save(mel_file_path, final_spec)\n",
    "                print(f\"Saved: {mel_file_path}\")\n",
    "            else:\n",
    "                print(f\"Failed to create mel-spectrogram for {species}/{rec_id}\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {species}/{rec_id}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 4. PREPROCESSING STATISTICS\n",
    "# ========================================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"PREPROCESSING PIPELINE SUMMARY:\")\n",
    "print(\"=\"*50)\n",
    "print(f\" Data split: {len(X_train)} train, {len(X_val)} val, {len(X_test)} test\")\n",
    "print(\" Audio preprocessing pipeline tested (no external dependencies)\")\n",
    "print(f\" Target audio length: {AUDIO_CONFIG['MAX_AUDIO_LENGTH']}s at {AUDIO_CONFIG['SAMPLE_RATE']}Hz\")\n",
    "print(f\" Target spectrogram shape: ({AUDIO_CONFIG['N_MELS']}, ~430)\")\n",
    "print(f\" Classes: {len(selected_species)} bird species\")\n",
    "print(f\" Noise reduction: Band-pass filtering + spectral subtraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data splits for next step\n",
    "SPLITS_DATA = {\n",
    "    'X_train': X_train,\n",
    "    'X_val': X_val,\n",
    "    'X_test': X_test,\n",
    "    'y_train': y_train,\n",
    "    'y_val': y_val,\n",
    "    'y_test': y_test,\n",
    "    'class_mapping': class_mapping,\n",
    "    'selected_species': selected_species\n",
    "}\n",
    "\n",
    "print(f\"\\n Next step: CNN model architecture and batch data generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_melspec(X, y, mel_dir):\n",
    "    \"\"\"Remove entries from X and y where mel-spec .npy file is missing.\"\"\"\n",
    "    missing_indices = []\n",
    "\n",
    "    for idx, row in X.iterrows():\n",
    "        rec_id = row['download_url'].split('/')[-2]\n",
    "        ebird_code = row['ebird_code']\n",
    "        filename = f\"{ebird_code}_{rec_id}.npy\"\n",
    "        mel_path = os.path.join(mel_dir, filename)\n",
    "\n",
    "        if not os.path.exists(mel_path):\n",
    "            print(f\"Missing mel-spec file: {filename}\")\n",
    "            missing_indices.append(idx)\n",
    "\n",
    "    # Drop and reset index\n",
    "    X_clean = X.drop(index=missing_indices).reset_index(drop=True)\n",
    "    y_clean = y.drop(index=missing_indices).reset_index(drop=True)\n",
    "\n",
    "    return X_clean, y_clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_melspec_dataset(X, y, mel_dir, target_shape=(128, 432)):\n",
    "    X_data, y_data = [], []\n",
    "\n",
    "    for _, row in X.iterrows():\n",
    "        rec_id = row['download_url'].split('/')[-2]\n",
    "        ebird_code = row['ebird_code']\n",
    "        filename = f\"{ebird_code}_{rec_id}.npy\"\n",
    "        mel_path = os.path.join(mel_dir, filename)\n",
    "\n",
    "        if os.path.exists(mel_path):\n",
    "            mel = np.load(mel_path)\n",
    "\n",
    "            # Resize or pad mel-spec\n",
    "            if mel.shape[1] < target_shape[1]:\n",
    "                # pad to the right\n",
    "                pad_width = target_shape[1] - mel.shape[1]\n",
    "                mel = np.pad(mel, ((0, 0), (0, pad_width)), mode='constant')\n",
    "            elif mel.shape[1] > target_shape[1]:\n",
    "                # crop to the target shape\n",
    "                mel = mel[:, :target_shape[1]]\n",
    "\n",
    "            X_data.append(mel)\n",
    "            y_data.append(y.loc[row.name])\n",
    "        else:\n",
    "            print(f\"Missing mel-spec file: {filename}\")\n",
    "    \n",
    "    X_data = np.array(X_data)\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "    return X_data, y_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_dir = '/home/sepehr/Documents/Audio-Project/machinelearning/dataset/filtered/melspec'\n",
    "\n",
    "# 1) Remove any rows whose mel-spec is missing\n",
    "X_train_df, y_train_sr = remove_missing_melspec(X_train, y_train, mel_dir)\n",
    "X_val_df,   y_val_sr   = remove_missing_melspec(X_val,   y_val,   mel_dir)\n",
    "X_test_df,  y_test_sr  = remove_missing_melspec(X_test,  y_test,  mel_dir)\n",
    "\n",
    "# 2) Merge the labels back into each DataFrame\n",
    "X_train_df = X_train_df.assign(class_id=y_train_sr.values)\n",
    "X_val_df   = X_val_df.assign(  class_id=y_val_sr.values)\n",
    "X_test_df  = X_test_df.assign( class_id=y_test_sr.values)\n",
    "\n",
    "# 3) Now you can inspect .head() safely\n",
    "print(X_train_df.shape, y_train_sr.shape)\n",
    "print(X_train_df.head())\n",
    "print(y_train_sr.head())\n",
    "\n",
    "print(X_val_df.shape, y_val_sr.shape)\n",
    "print(X_val_df.head())\n",
    "print(y_val_sr.head())\n",
    "\n",
    "print(X_test_df.shape, y_test_sr.shape)\n",
    "print(X_test_df.head())\n",
    "print(y_test_sr.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_mel(rec_id, ebird_code, melspec_dir):\n",
    "    mel = np.load(os.path.join(melspec_dir, f\"{ebird_code}_{rec_id}.npy\"))\n",
    "    mean_feat = mel.mean(axis=1)\n",
    "    std_feat  = mel.std(axis=1)\n",
    "    return np.hstack([mean_feat, std_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feat_matrix_from_mel(X_df, melspec_dir):\n",
    "    feats, labs = [], []\n",
    "    for _, row in X_df.iterrows():\n",
    "        rec_id     = row['download_url'].rstrip('/').split('/')[-2]\n",
    "        code       = row['ebird_code']\n",
    "        feats.append(extract_features_from_mel(rec_id, code, melspec_dir))\n",
    "        labs.append(row['class_id'])\n",
    "    return np.vstack(feats), np.array(labs)\n",
    "\n",
    "MEL_DIR = '/home/sepehr/Documents/Audio-Project/machinelearning/dataset/filtered/melspec'\n",
    "\n",
    "X_train_feat, y_train_feat = make_feat_matrix_from_mel(X_train_df, mel_dir)\n",
    "X_val_feat,   y_val_feat   = make_feat_matrix_from_mel(X_val_df,   mel_dir)\n",
    "X_test_feat,  y_test_feat  = make_feat_matrix_from_mel(X_test_df,  mel_dir)\n",
    "\n",
    "print(\"Feature shapes:\", \n",
    "      X_train_feat.shape, \n",
    "      X_val_feat.shape, \n",
    "      X_test_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Build feature matrices\n",
    "X_train_feat, y_train_feat = make_feat_matrix_from_mel(X_train_df, mel_dir)\n",
    "X_val_feat,   y_val_feat   = make_feat_matrix_from_mel(X_val_df,   mel_dir)\n",
    "X_test_feat,  y_test_feat  = make_feat_matrix_from_mel(X_test_df,  mel_dir)\n",
    "\n",
    "print(\"Shapes:\", X_train_feat.shape, X_val_feat.shape, X_test_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = load_melspec_dataset(X_train_np, y_train_np, mel_dir)\n",
    "# print(X_train.shape)\n",
    " \n",
    "# X_test, y_test = load_melspec_dataset(X_test_np, y_test_np, mel_dir)\n",
    "# print(X_test.shape)\n",
    "\n",
    "# X_val, y_val = load_melspec_dataset(X_val_np, y_val_np, mel_dir)\n",
    "# print(X_val.shape)\n",
    "\n",
    "\n",
    "# X_val = X_val.reshape((X_val.shape[0], -1))\n",
    "# X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "# X_test = X_test.reshape((X_test.shape[0], -1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline      import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create shorthands for convenience\n",
    "X_tr, y_tr = X_train_feat, y_train_feat\n",
    "X_te, y_te = X_test_feat,  y_test_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf',     RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "])\n",
    "RF_pipe.fit(X_tr, y_tr)\n",
    "pred = RF_pipe.predict(X_te)\n",
    "\n",
    "print(\"RF (handcrafted) acc:\", accuracy_score(y_te, pred))\n",
    "print(classification_report(y_test_feat, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('sgd',   SGDClassifier(\n",
    "                  loss='log_loss',        # logistic\n",
    "                  learning_rate='optimal',\n",
    "                  max_iter=1000, tol=1e-3,\n",
    "                  random_state=42))\n",
    "])\n",
    "sgd_pipe.fit(X_tr, y_tr)\n",
    "pred_sgd = sgd_pipe.predict(X_te)\n",
    "print(\"SGD Accuracy:\", accuracy_score(y_te, pred_sgd))\n",
    "print(classification_report(y_te, pred_sgd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_tr, y_tr)\n",
    "pred_nb = nb.predict(X_te)\n",
    "print(\"NB Accuracy:\", accuracy_score(y_te, pred_nb))\n",
    "print(classification_report(y_te, pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_tr, y_tr)\n",
    "pred_dt = dt.predict(X_te)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_te, pred_dt))\n",
    "print(classification_report(y_te, pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('knn',   KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "knn_pipe.fit(X_tr, y_tr)\n",
    "pred_knn = knn_pipe.predict(X_te)\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_te, pred_knn))\n",
    "print(classification_report(y_te, pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('svm',   SVC(kernel='rbf', C=1.0, random_state=42))\n",
    "])\n",
    "svm_pipe.fit(X_tr, y_tr)\n",
    "pred_svm = svm_pipe.predict(X_te)\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_te, pred_svm))\n",
    "print(classification_report(y_te, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 726237,
     "sourceId": 1487019,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
